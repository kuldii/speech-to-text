{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598b5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pip-tools\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "710c271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip-compile --strip-extras requirements.in\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2396dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "\n",
    "# Cek device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load dataset LibriSpeech (dev-clean)\n",
    "train_dataset = LIBRISPEECH(\"./datasets\", url=\"dev-clean\", download=False) # Jika blm punya dataset, bisa set True\n",
    "test_dataset = LIBRISPEECH(\"./datasets\", url=\"test-clean\", download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3ada68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing fungsi: ekstrak Mel Spectrogram dari audio\n",
    "# Peringatan: n_mels=128 mungkin terlalu besar untuk n_fft=400 (n_freqs=201)\n",
    "# Jika ingin menghilangkan warning, bisa turunkan n_mels (misal 80) atau naikkan n_fft\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=80,  # ubah dari 128 ke 80 agar tidak ada filterbank yang nol\n",
    "    n_fft=400,\n",
    "    hop_length=160,\n",
    ").to(device)\n",
    "\n",
    "# Buat collate_fn untuk padding batch data audio dan teks\n",
    "def collate_fn(batch):\n",
    "    waveforms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "\n",
    "    for waveform, sample_rate, transcript, _, _, _ in batch:\n",
    "        waveform = waveform.to(device)\n",
    "        # ekstrak fitur\n",
    "        mel_spec = mel_spectrogram(waveform).squeeze(0).transpose(0, 1)  # (time, mel)\n",
    "        waveforms.append(mel_spec)\n",
    "\n",
    "        # ubah transcript ke label index\n",
    "        label = text_to_index(transcript.lower())\n",
    "        labels.append(torch.tensor(label, dtype=torch.long))\n",
    "\n",
    "        input_lengths.append(mel_spec.shape[0])\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    # Pad input fitur (waveforms) dan label (teks)\n",
    "    waveforms = nn.utils.rnn.pad_sequence(waveforms, batch_first=True)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    return waveforms, labels, torch.tensor(input_lengths), torch.tensor(label_lengths)\n",
    "\n",
    "# Map karakter ke index (tokenizer sederhana)\n",
    "char_map_str = \" abcdefghijklmnopqrstuvwxyz'\"\n",
    "char_map = {c: i + 1 for i, c in enumerate(char_map_str)}  # 0 untuk padding\n",
    "\n",
    "def text_to_index(text):\n",
    "    return [char_map.get(c, 0) for c in text]\n",
    "\n",
    "def index_to_text(indices):\n",
    "    inv_map = {v: k for k, v in char_map.items()}\n",
    "    return \"\".join([inv_map.get(i, \"\") for i in indices])\n",
    "\n",
    "# Dataset dan DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model RNN sederhana dengan CTC Loss\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, time, feat)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)  # (batch, time, output_dim)\n",
    "        return out.log_softmax(dim=-1)\n",
    "\n",
    "input_dim = 80  # disesuaikan dengan n_mels pada mel_spectrogram\n",
    "hidden_dim = 256\n",
    "output_dim = len(char_map) + 1  # plus blank token untuk CTC\n",
    "\n",
    "model = SpeechRecognitionModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Loss function CTC\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop dengan print progress\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (waveforms, labels, input_lengths, label_lengths) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(waveforms)  # (batch, time, output_dim)\n",
    "        outputs = outputs.transpose(0, 1)  # CTC expects (time, batch, output)\n",
    "\n",
    "        loss = ctc_loss(outputs, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(f\"Batch {batch_idx+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch selesai. Rata-rata loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# Inference decode: greedy decoding (ambil argmax di output)\n",
    "def greedy_decoder(output):\n",
    "    argmaxes = torch.argmax(output, dim=-1)\n",
    "    decoded_batch = []\n",
    "    for args in argmaxes:\n",
    "        decoded = []\n",
    "        prev = 0\n",
    "        for i in args:\n",
    "            if i != prev and i != 0:\n",
    "                decoded.append(i.item())\n",
    "            prev = i\n",
    "        decoded_batch.append(index_to_text(decoded))\n",
    "    return decoded_batch\n",
    "\n",
    "# Jalankan training\n",
    "print(\"Training mulai...\")\n",
    "train_loss = train_epoch()\n",
    "print(f\"Training loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"speech_recognition_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model berhasil disimpan ke speech_recognition_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840cae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation loop\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels, input_lengths, label_lengths in test_loader:\n",
    "            outputs = model(waveforms)\n",
    "            decoded_preds = greedy_decoder(outputs)\n",
    "            for pred in decoded_preds[:5]:  # tampilkan 5 hasil prediksi\n",
    "                print(\"Prediksi:\", pred)\n",
    "            break\n",
    "\n",
    "print(\"Evaluasi contoh prediksi...\")\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734efa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for waveforms, labels, input_lengths, label_lengths in test_loader:\n",
    "        outputs = model(waveforms)\n",
    "        decoded_preds = greedy_decoder(outputs)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        # Plot Mel Spectrogram dari sample pertama di batch\n",
    "        axes[0].imshow(waveforms[0].cpu().T, aspect='auto', origin='lower')\n",
    "        axes[0].set_title(\"Mel Spectrogram\")\n",
    "        axes[0].set_xlabel(\"Frame\")\n",
    "        axes[0].set_ylabel(\"Mel Bin\")\n",
    "        # Tampilkan prediksi hasil decoding\n",
    "        axes[1].axis('off')\n",
    "        axes[1].text(0.1, 0.5, f\"Prediksi:\\n{decoded_preds[0]}\", fontsize=14)\n",
    "        plt.show()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
